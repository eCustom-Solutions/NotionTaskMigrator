migrate_tags.js
---------------
// migrate_tags.js
// ----------------
// Orchestrates migration of “related” pages from Global Tags DB → Brands/Verticals/Departments
//
// Usage: node migrate_tags.js [limit]
//   - If you supply a numeric argument, the script will stop after migrating that many related pages.
//   - If omitted, it defaults to 1 (dry-run). To process all pages, pass a very large number or remove the limit logic.

require('dotenv').config();
const notion          = require('./services/notion_client');
const logger          = require('./services/logger');
const linkStore       = require('./services/link_store');
const transformTagPage = require('./transformations/tag_transformer');
const { writeToDBB }  = require('./services/write_task');

// ── CONFIG ─────────────────────────────────────────────────────────────────────
const DEFAULT_LIMIT = 1;

// ── Environment / Target DB IDs ───────────────────────────────────────────────
const GLOBAL_TAGS_DB_ID = process.env.GLOBAL_TAGS_DB_ID;
const TARGET_DB_IDS = {
    Brand:    process.env.BRANDS_DB_ID,
    Vertical: process.env.VERTICALS_DB_ID,
    Team:     process.env.DEPARTMENTS_DB_ID
};

// ── Helper: stream all pages from a Notion database (paginated) ──────────────
async function* streamDB(dbId) {
    let cursor = undefined;
    do {
        const response = await notion.databases.query({
            database_id: dbId,
            page_size: 100,
            start_cursor: cursor
        });
        for (const page of response.results) {
            yield page;
        }
        cursor = response.has_more ? response.next_cursor : undefined;
    } while (cursor);
}

// ── Main orchestrator ────────────────────────────────────────────────────────
async function main() {
    // 1) Parse CLI argument for limit (dry-run)
    const rawLimit = process.argv[2];
    const limit = rawLimit ? parseInt(rawLimit, 10) : DEFAULT_LIMIT;
    if (isNaN(limit) || limit < 1) {
        console.error('⚠️  Invalid limit provided. Please pass a positive integer or omit for default 1.');
        process.exit(1);
    }

    logger.info('▶️  Starting Tag Migrator');
    logger.info(`   Source (Global Tags DB): ${GLOBAL_TAGS_DB_ID}`);
    logger.info(`   Dry-run limit: ${limit}\n`);

    let migratedCount = 0;

    // 2) Iterate all pages in Global Tags DB
    for await (const tagPage of streamDB(GLOBAL_TAGS_DB_ID)) {
        // 2a) Read the Tag title exactly (Notion Title → plain_text)
        const titleArray = tagPage.properties['Tag']?.title || [];
        const tagType = titleArray[0]?.plain_text?.trim() || null;

        // 2b) Only proceed if Tag is exactly "Brand", "Vertical", or "Team"
        if (!TARGET_DB_IDS[tagType]) {
            continue;
        }

        logger.info(`🔎 Processing Global Tag page (type="${tagType}"): ${tagPage.id}`);

        // 3) Read its “Related Global Tags DB” relations array
        //    Each item is { id: <relatedPageId>, ... }
        const relations = tagPage.properties['Related Global Tags DB']?.relation || [];
        if (relations.length === 0) {
            logger.info(`   ↳ No related pages found for this ${tagType} tag → skipping.`);
            continue;
        }

        // 4) For each related page, migrate it into the target DB
        const targetDbId = TARGET_DB_IDS[tagType];
        for (const rel of relations) {
            if (migratedCount >= limit) {
                logger.info(`🏁 Reached migration limit (${limit}). Exiting.`);
                process.exit(0);
            }

            const sourceId = rel.id;

            // 4a) Idempotency: skip if already migrated under "tags"
            const existing = await linkStore.load(sourceId, 'tags').catch(() => null);
            if (existing && existing.status === 'success') {
                logger.info(`   ↩️  Skipping related page ${sourceId} (already migrated).`);
                continue;
            }

            try {
                // 4b) Fetch full page object from Notion
                logger.info(`   📥 Fetching related page: ${sourceId}`);

                // Log before URL
                const beforeUrl = `https://notion.so/${sourceId.replace(/-/g, '')}`;
                logger.info(`   🔗 Before URL: ${beforeUrl}`);

                const page = await notion.pages.retrieve({ page_id: sourceId });

                // 4c) Build a create-page payload via transformer
                logger.info(`   🛠  Transforming page for target DB "${tagType}"`);
                const payload = await transformTagPage(page);
                payload.parent = { database_id: targetDbId };

                // 4d) Write into the target DB (Brands/Verticals/Departments)
                logger.info(`   🚀 Writing to target DB (${targetDbId})`);
                const created = await writeToDBB(payload, targetDbId);
                logger.info(`   ✅ Created new page ${created.id} in target.`);

                // Log after URL
                const afterUrl = `https://notion.so/${created.id.replace(/-/g, '')}`;
                logger.info(`   🔗 After URL: ${afterUrl}`);

                // 4e) Record the migration in link_store under "tags"
                await linkStore.save({
                    sourceId,
                    targetId: created.id,
                    status: 'success',
                    syncedAt: new Date().toISOString()
                }, 'tags');
                logger.info(`   💾 Recorded link (${sourceId} → ${created.id}) under "tags"`);

                migratedCount += 1;
            } catch (err) {
                // 4f) On failure, still save a “fail” entry so we don’t retry endlessly
                logger.error(`   ❌ Failed to migrate related page ${sourceId}`, err);
                await linkStore.save({
                    sourceId,
                    targetId: null,
                    status: 'fail',
                    syncedAt: new Date().toISOString()
                }, 'tags');
            }
        }
    }

    logger.info(`\n🏁 Migration complete. Total related pages processed: ${migratedCount}`);
}

// Invoke main(), catching unexpected errors
main().catch((err) => {
    console.error('Fatal error in migrate_tags.js:', err);
    process.exit(1);
});

migrate_tasks.js
----------------
// migrate_tasks.js
// ------------
// Orchestrates the streaming ETL from SM Tasks DB to CENT Tasks DB
// Usage: node syncTasks.js
// Ensure .env contains NOTION_SM_TASKS_DB_ID and NOTION_CENT_DB_ID

require('dotenv').config();
const { getTasksFromDBA }      = require('./services/fetch_tasks');
const writeToDBB               = require('./services/write_task').writeToDBB;
const linkStore                = require('./services/link_store');
const transform                = require('./transformations/generic_transformer');
const mapSpec                  = require('./transformations/sm_tasks_map');
const logger = require('./services/logger');

const SM_DB_ID   = process.env.NOTION_SM_TASKS_DB_ID;
const CENT_DB_ID = process.env.NOTION_CENT_DB_ID;

async function main() {
    logger.info(`▶️  Starting Task Migrator`);
    logger.info(`   Source (SM): ${SM_DB_ID}`);
    logger.info(`   Target (CENT): ${CENT_DB_ID}\n`);

    let processed = 0;
    for await (const page of getTasksFromDBA(SM_DB_ID)) {
        const sourceId = page.id;

        // Idempotency: skip if already migrated
        const existing = await linkStore.load(sourceId).catch(() => null);
        if (existing && existing.status === 'success') {
            // logger.info(`↩️ Skipping ${sourceId} (already succeeded)`);
            // logger.info(`ℹ️ Link already exists in store:`, existing);
            continue;
        }

        logger.info(`🛠 Transforming page ${sourceId}`);
        const payload = await transform(page, mapSpec);

        // Write to CENT DB
        try {
            logger.info(`🚀 Writing page ${sourceId} to CENT DB`);
            const result = await writeToDBB(payload, CENT_DB_ID);
            logger.info(`✅ Write result for ${sourceId}:`, result);
            logger.info(`✅ Migrated ${sourceId} → ${result.id}`);

            // Record the link
            await linkStore.save({
                sourceId,
                targetId: result.id,
                status: 'success',
                syncedAt: new Date().toISOString()
            });
            logger.info(`💾 Link saved for ${sourceId}`);

        } catch (err) {
            // More context on failure:
            console.error(`❌ Failed to migrate ${sourceId}`);
            const notionUrl = `https://www.notion.so/${sourceId.replace(/-/g, '')}`; console.error(`🔗 Review in Notion: ${notionUrl}`);
            console.error('• Notion error:', err);

            // still record failure to avoid infinite retry loops
            await linkStore.save({
                sourceId,
                targetId: null,
                status: 'fail',
                syncedAt: new Date().toISOString()
            });
            logger.info(`💾 Link saved for ${sourceId}`);
        }

        processed++;
    }

    logger.info(`\n🏁 Migration complete! ${processed} pages processed.`);
}

main().catch(err => {
    console.error('Fatal error in syncTasks:', err);
    process.exit(1);
});

file_contents_report.txt
------------------------
migrate_tags.js
---------------
// migrate_tags.js
// ----------------
// Orchestrates migration of “related” pages from Global Tags DB → Brands/Verticals/Departments
//
// Usage: node migrate_tags.js [limit]
//   - If you supply a numeric argument, the script will stop after migrating that many related pages.
//   - If omitted, it defaults to 1 (dry-run). To process all pages, pass a very large number or remove the limit logic.

require('dotenv').config();
const notion          = require('./services/notion_client');
const logger          = require('./services/logger');
const linkStore       = require('./services/link_store');
const transformTagPage = require('./transformations/tag_transformer');
const { writeToDBB }  = require('./services/write_task');

// ── CONFIG ─────────────────────────────────────────────────────────────────────
const DEFAULT_LIMIT = 1;

// ── Environment / Target DB IDs ───────────────────────────────────────────────
const GLOBAL_TAGS_DB_ID = process.env.GLOBAL_TAGS_DB_ID;
const TARGET_DB_IDS = {
    Brand:    process.env.BRANDS_DB_ID,
    Vertical: process.env.VERTICALS_DB_ID,
    Team:     process.env.DEPARTMENTS_DB_ID
};

// ── Helper: stream all pages from a Notion database (paginated) ──────────────
async function* streamDB(dbId) {
    let cursor = undefined;
    do {
        const response = await notion.databases.query({
            database_id: dbId,
            page_size: 100,
            start_cursor: cursor
        });
        for (const page of response.results) {
            yield page;
        }
        cursor = response.has_more ? response.next_cursor : undefined;
    } while (cursor);
}

// ── Main orchestrator ────────────────────────────────────────────────────────
async function main() {
    // 1) Parse CLI argument for limit (dry-run)
    const rawLimit = process.argv[2];
    const limit = rawLimit ? parseInt(rawLimit, 10) : DEFAULT_LIMIT;
    if (isNaN(limit) || limit < 1) {
        console.error('⚠️  Invalid limit provided. Please pass a positive integer or omit for default 1.');
        process.exit(1);
    }

    logger.info('▶️  Starting Tag Migrator');
    logger.info(`   Source (Global Tags DB): ${GLOBAL_TAGS_DB_ID}`);
    logger.info(`   Dry-run limit: ${limit}\n`);

    let migratedCount = 0;

    // 2) Iterate all pages in Global Tags DB
    for await (const tagPage of streamDB(GLOBAL_TAGS_DB_ID)) {
        // 2a) Read the Tag title exactly (Notion Title → plain_text)
        const titleArray = tagPage.properties['Tag']?.title || [];
        const tagType = titleArray[0]?.plain_text?.trim() || null;

        // 2b) Only proceed if Tag is exactly "Brand", "Vertical", or "Team"
        if (!TARGET_DB_IDS[tagType]) {
            continue;
        }

        logger.info(`🔎 Processing Global Tag page (type="${tagType}"): ${tagPage.id}`);

        // 3) Read its “Related Global Tags DB” relations array
        //    Each item is { id: <relatedPageId>, ... }
        const relations = tagPage.properties['Related Global Tags DB']?.relation || [];
        if (relations.length === 0) {
            logger.info(`   ↳ No related pages found for this ${tagType} tag → skipping.`);
            continue;
        }

        // 4) For each related page, migrate it into the target DB
        const targetDbId = TARGET_DB_IDS[tagType];
        for (const rel of relations) {
            if (migratedCount >= limit) {
                logger.info(`🏁 Reached migration limit (${limit}). Exiting.`);
                process.exit(0);
            }

            const sourceId = rel.id;

            // 4a) Idempotency: skip if already migrated under "tags"
            const existing = await linkStore.load(sourceId, 'tags').catch(() => null);
            if (existing && existing.status === 'success') {
                logger.info(`   ↩️  Skipping related page ${sourceId} (already migrated).`);
                continue;
            }

            try {
                // 4b) Fetch full page object from Notion
                logger.info(`   📥 Fetching related page: ${sourceId}`);

                // Log before URL
                const beforeUrl = `https://notion.so/${sourceId.replace(/-/g, '')}`;
                logger.info(`   🔗 Before URL: ${beforeUrl}`);

                const page = await notion.pages.retrieve({ page_id: sourceId });

                // 4c) Build a create-page payload via transformer
                logger.info(`   🛠  Transforming page for target DB "${tagType}"`);
                const payload = await transformTagPage(page);
                payload.parent = { database_id: targetDbId };

                // 4d) Write into the target DB (Brands/Verticals/Departments)
                logger.info(`   🚀 Writing to target DB (${targetDbId})`);
                const created = await writeToDBB(payload, targetDbId);
                logger.info(`   ✅ Created new page ${created.id} in target.`);

                // Log after URL
                const afterUrl = `https://notion.so/${created.id.replace(/-/g, '')}`;
                logger.info(`   🔗 After URL: ${afterUrl}`);

                // 4e) Record the migration in link_store under "tags"
                await linkStore.save({
                    sourceId,
                    targetId: created.id,
                    status: 'success',
                    syncedAt: new Date().toISOString()
                }, 'tags');
                logger.info(`   💾 Recorded link (${sourceId} → ${created.id}) under "tags"`);

                migratedCount += 1;
            } catch (err) {
                // 4f) On failure, still save a “fail” entry so we don’t retry endlessly
                logger.error(`   ❌ Failed to migrate related page ${sourceId}`, err);
                await linkStore.save({
                    sourceId,
                    targetId: null,
                    status: 'fail',
                    syncedAt: new Date().toISOString()
                }, 'tags');
            }
        }
    }

    logger.info(`\n🏁 Migration complete. Total related pages processed: ${migratedCount}`);
}

// Invoke main(), catching unexpected errors
main().catch((err) => {
    console.error('Fatal error in migrate_tags.js:', err);
    process.exit(1);
});

migrate_tasks.js
----------------
// migrate_tasks.js
// ------------
// Orchestrates the streaming ETL from SM Tasks DB to CENT Tasks DB
// Usage: node syncTasks.js
// Ensure .env contains NOTION_SM_TASKS_DB_ID and NOTION_CENT_DB_ID

require('dotenv').config();
const { getTasksFromDBA }      = require('./services/fetch_tasks');
const writeToDBB               = require('./services/write_task').writeToDBB;
const linkStore                = require('./services/link_store');
const transform                = require('./transformations/generic_transformer');
const mapSpec                  = require('./transformations/sm_tasks_map');
const logger = require('./services/logger');

const SM_DB_ID   = process.env.NOTION_SM_TASKS_DB_ID;
const CENT_DB_ID = process.env.NOTION_CENT_DB_ID;

async function main() {
    logger.info(`▶️  Starting Task Migrator`);
    logger.info(`   Source (SM): ${SM_DB_ID}`);
    logger.info(`   Target (CENT): ${CENT_DB_ID}\n`);

    let processed = 0;
    for await (const page of getTasksFromDBA(SM_DB_ID)) {
        const sourceId = page.id;

        // Idempotency: skip if already migrated
        const existing = await linkStore.load(sourceId).catch(() => null);
        if (existing && existing.status === 'success') {
            // logger.info(`↩️ Skipping ${sourceId} (already succeeded)`);
            // logger.info(`ℹ️ Link already exists in store:`, existing);
            continue;
        }

        logger.info(`🛠 Transforming page ${sourceId}`);
        const payload = await transform(page, mapSpec);

        // Write to CENT DB
        try {
            logger.info(`🚀 Writing page ${sourceId} to CENT DB`);
            const result = await writeToDBB(payload, CENT_DB_ID);
            logger.info(`✅ Write result for ${sourceId}:`, result);
            logger.info(`✅ Migrated ${sourceId} → ${result.id}`);

            // Record the link
            await linkStore.save({
                sourceId,
                targetId: result.id,
                status: 'success',
                syncedAt: new Date().toISOString()
            });
            logger.info(`💾 Link saved for ${sourceId}`);

        } catch (err) {
            // More context on failure:
            console.error(`❌ Failed to migrate ${sourceId}`);
            const notionUrl = `https://www.notion.so/${sourceId.replace(/-/g, '')}`; console.error(`🔗 Review in Notion: ${notionUrl}`);
            console.error('• Notion error:', err);

            // still record failure to avoid infinite retry loops
            await linkStore.save({
                sourceId,
                targetId: null,
                status: 'fail',
                syncedAt: new Date().toISOString()
            });
            logger.info(`💾 Link saved for ${sourceId}`);
        }

        processed++;
    }

    logger.info(`\n🏁 Migration complete! ${processed} pages processed.`);
}

main().catch(err => {
    console.error('Fatal error in syncTasks:', err);
    process.exit(1);
});



transformations/sm_tasks_map.js
-------------------------------
// transformations/sm_tasks_map.js
// -------------------------------

const { resolveOrCreateRelationPages } = require('../services/relation_resolver');

module.exports = {
    mappings: {
        'Name':       'Name',
        'Brand':      'Brands',
        'Status':     'Social Media Status',
        // 'Teammates':  'People',   // source "Teammates" → target "People"
        'Due Date':   'Due',
        'Link':       'Link',
        'Comments':   'Comments',
    },

    hooks: {
        'Social Media Status': (sourceValue) => {
            const name = sourceValue.status?.name;
            return { status: { name: name || null } };
        },
        'Brands': async (sourceValue) => {
            const brandNames = sourceValue.relation?.length > 0
                ? await Promise.all(sourceValue.relation.map(async rel => {
                    // Fetch source Brand page to read its Name
                    const page = await notion.pages.retrieve({ page_id: rel.id });
                    return page.properties['Name']?.title?.[0]?.plain_text || null;
                }))
                : [];

            // Clean out nulls
            const filteredBrandNames = brandNames.filter(Boolean);

            if (filteredBrandNames.length === 0) {
                return { relation: [] };
            }

            const CENT_DB_ID = process.env.NOTION_CENT_DB_ID;

            const pageIds = await resolveOrCreateRelationPages({
                targetDbId: CENT_DB_ID,
                relationPropName: 'Brands',
                sourceNames: filteredBrandNames,
                nameProp: 'Name'
            });

            return { relation: pageIds.map(id => ({ id })) };
        },
        'Link': (sourceValue) => {
            const firstFile = sourceValue.files?.[0];
            const firstUrl = firstFile?.external?.url || firstFile?.file?.url || null;

            return {
                url: firstUrl
            };
        }

        // // Updated People hook to use the relation_resolver
        // 'People': async (sourceValue) => {
        //     // Extract names from the source multi_select “Teammates”
        //     const teammateNames = sourceValue.multi_select?.map(option => option.name) || [];
        //
        //     if (teammateNames.length === 0) {
        //         return null;
        //     }
        //
        //     // Call our helper:
        //     //  • targetDbId: your CENT DB ID (pull from env or pass in context)
        //     //  • relationPropName: “People”
        //     //  • sourceNames: array of teammate names
        //     //  • nameProp: the title property in the People-relation DB (usually "Name")
        //     const CENT_DB_ID = process.env.NOTION_CENT_DB_ID;
        //
        //     const pageIds = await resolveOrCreateRelationPages({
        //         targetDbId: CENT_DB_ID,
        //         relationPropName: 'People',
        //         sourceNames: teammateNames,
        //         nameProp: 'Full Name'
        //     });
        //
        //     // Return the array in Notion’s expected shape:
        //     return { relation: pageIds.map(id => ({ id })) };
        // }
    },

    postProcess: async (payload) => {
        payload.properties['Department'] = {
            relation: [
                { id: '1de6824d5503804c91d4fdf1d5303433' }  // Social Media Management
            ]
        };
        return payload;
    }
};

transformations/tag_transformer.js
----------------------------------
// transformations/tag_transformer.js

const notion = require('../services/notion_client');

module.exports = async function transformTagPage(page) {
    // ── Build a minimal payload object
    // The calling code will set `parent.database_id` before using this.
    const result = {
        parent: {},        // ⬅︎ caller will fill in the correct target DB ID
        properties: {
            // Copy the Title property from the source page
            Name: {
                title: page.properties['Name']?.title || []
            }
        }
    };

    // ── Copy over the emoji/icon if one is present
    if (page.icon && page.icon.type === 'emoji') {
        result.icon = {
            type: 'emoji',
            emoji: page.icon.emoji
        };
    }

    // ── Fetch all of this page’s child blocks (if any)
    //    We iterate with pagination (page_size=100) to pull every block.
    const blocks = [];
    let cursor = undefined;

    do {
        const response = await notion.blocks.children.list({
            block_id: page.id,
            page_size: 100,
            start_cursor: cursor
        });

        blocks.push(...response.results);
        cursor = response.has_more ? response.next_cursor : undefined;
    } while (cursor);

    // If we found any blocks, attach them as `children` in the payload
    if (blocks.length > 0) {
        result.children = blocks;
    }

    return result;
};

transformations/generic_transformer.js
--------------------------------------
// transformations/generic_transformer.js
// --------------------------------------
// A generic transformer that, given a Notion page and a mapping spec,
// builds the `properties` payload for creating/updating a page in the target DB.

const notion = require('../services/notion_client');

module.exports = async function transform(page, map) {
    const result = {properties: {}};

    for (const [sourceKey, targetKey] of Object.entries(map.mappings)) {
        const sourceValue = page.properties[sourceKey];
        if (sourceValue == null) {
            // no such property on source page
            continue;
        }

        if (map.hooks && typeof map.hooks[targetKey] === 'function') {
            const hookResult = await map.hooks[targetKey](sourceValue);
            result.properties[targetKey] = hookResult;
        } else {
            const type = sourceValue.type;

            if (type === 'title') {
                result.properties[targetKey] = {
                    title: sourceValue.title
                };
            } else if (!type) {
                console.error(`❗ sourceValue.type is undefined for property "${sourceKey}"`);
                console.error(`→ sourceValue was:`, sourceValue);
                throw new Error(`Cannot infer type for property "${sourceKey}"`);
            } else {
                result.properties[targetKey] = { [type]: sourceValue[type] };
            }
        }
    }

    // Optional post-processing hook
    if (typeof map.postProcess === 'function') {
        await map.postProcess(result, page);
    }

    // Optional: skip copying blocks if map opts in
    const skipBlocks = map?.options?.skipBlocks === true;

    if (!skipBlocks) {
        // Fetch and attach blocks (page contents)
        const blocks = [];
        let cursor = undefined;

        do {
            const response = await notion.blocks.children.list({
                block_id: page.id,
                page_size: 100,
                start_cursor: cursor
            });

            blocks.push(...response.results);
            cursor = response.has_more ? response.next_cursor : undefined;
        } while (cursor);

        if (blocks.length > 0) {
            result.children = blocks;
        }
    }

    return result;
};

models/Link.js
--------------
// models/Link.js
// --------------
// Basic Link class used by link_store.js
// Represents a mapping from a source page to a target page.

class Link {
    /**
     * @param {string} sourceId
     * @param {string} targetId
     * @param {string} [status='success']
     * @param {string} [syncedAt=now]
     */
    constructor(sourceId, targetId, status = 'success', syncedAt = new Date().toISOString()) {
        this.sourceId = sourceId;
        this.targetId = targetId;
        this.status = status;
        this.syncedAt = syncedAt;
    }
}

module.exports = Link;

scripts/stream_db_contents.js
-----------------------------
// scripts/stream_db_contents.js
// ---------------------

const path = require('path');

// Force dotenv to load from project root
require('dotenv').config({ path: path.resolve(__dirname, '../.env') });

const notion = require('../services/notion_client');  // still correct

const SM_DB_ID   = process.env.NOTION_SM_TASKS_DB_ID;
const CENT_DB_ID = process.env.NOTION_CENT_DB_ID;
const GLOBAL_TAGS_DB_ID = process.env.GLOBAL_TAGS_DB_ID

// Debug: confirm values loaded
console.log('cwd:', process.cwd());
console.log('dirname:', __dirname);
console.log('SM_DB_ID:', SM_DB_ID);
console.log('CENT_DB_ID:', CENT_DB_ID);
console.log('GLOBAL_TAGS_DB_ID', GLOBAL_TAGS_DB_ID);

async function* streamDB(dbId) {
    let cursor = undefined;

    do {
        const response = await notion.databases.query({
            database_id: dbId,
            page_size: 100,
            start_cursor: cursor,
        });

        for (const page of response.results) {
            yield page;
        }

        cursor = response.has_more ? response.next_cursor : undefined;
    } while (cursor);
}

async function main() {
    console.log(`▶️  Streaming SM Tasks DB (${GLOBAL_TAGS_DB_ID})`);
    for await (const page of streamDB(GLOBAL_TAGS_DB_ID)) {
        console.log(`SM Page ID: ${page.id}`);
        console.dir(page.properties, { depth: null });
        console.log('---');
    }

    // console.log(`\n▶️  Streaming CENT Tasks DB (${CENT_DB_ID})`);
    // for await (const page of streamDB(CENT_DB_ID)) {
    //     console.log(`CENT Page ID: ${page.id}`);
    //     console.dir(page.properties, { depth: null });
    //     console.log('---');
    // }

    console.log(`\n🏁 Done streaming both databases.`);
}

main().catch(err => {
    console.error('Fatal error:', err);
    process.exit(1);
});

services/write_task.js
----------------------
// services/write_task.js
// ---------------------
// Writes a single transformed task into Notion DB B and returns the created page.

const notion = require('./notion_client');

/**
 * @param {object} transformedTask  – shape: { properties: { ... }, children?: [...] }
 * @param {string} dbId             – Notion Database B ID
 * @returns {Promise<object>}       – Notion response (including `id` of new page)
 */
async function writeToDBB(transformedTask, dbId) {
    const payload = {
        parent: { database_id: dbId },
        properties: transformedTask.properties,
    };

    // If your transformer produces children blocks, include them
    if (transformedTask.children) {
        payload.children = transformedTask.children;
    }

    const response = await notion.pages.create(payload);
    return response;
}

module.exports = { writeToDBB };

services/notion_client.js
-------------------------
// services/notion_client.js
// ----------------------
// Centralized Notion client with rate-limiting via Bottleneck.
// Provides wrapped methods for all Notion API calls used in Task Migrator.
// Exported functions are safe to call directly—each is throttled to respect API limits.

const { Client } = require('@notionhq/client');
const Bottleneck = require('bottleneck');
require('dotenv').config(); // Ensure NOTION_API_KEY is loaded

// ── 1) Configure Bottleneck limiter to 3 requests/sec
const limiter = new Bottleneck({
    reservoir: 3,                   // start with 3 tokens
    reservoirRefreshAmount: 3,      // refill to 3 tokens...
    reservoirRefreshInterval: 1000, // ...every 1000ms (1 sec)
    maxConcurrent: 1,              // execute one at a time for safety
});

// ── 2) Initialize Notion client using API key
const notion = new Client({ auth: process.env.NOTION_API_KEY });

// ── 3) Helper to wrap any Notion SDK method with rate limiting
const _wrap = (fn) => {
    return (...args) => limiter.schedule(() => fn(...args));
};

// ── 4) Export limited versions of the Notion API methods used
module.exports = {
    // Databases
    databases: {
        retrieve: _wrap(notion.databases.retrieve.bind(notion)),
        query:    _wrap(notion.databases.query.bind(notion)),
    },

    // Pages
    pages: {
        create:    _wrap(notion.pages.create.bind(notion)),
        update:    _wrap(notion.pages.update.bind(notion)),
        retrieve:  _wrap(notion.pages.retrieve.bind(notion)),

        // Page properties
        properties: {
            retrieve: _wrap(notion.pages.properties.retrieve.bind(notion)),
        },
    },

    // Blocks (if needed later)
    blocks: {
        children: {
            list: _wrap(notion.blocks.children.list.bind(notion)),
        },
    },

    // Expose limiter for testing or introspection
    __limiter: limiter,
};

// ── 5) Testing this module
// In your tests, you can:
//  - Mock `@notionhq/client` methods to return fixed values.
//  - Verify that calling exported methods returns promises.
//  - Inspect `__limiter` metrics (e.g., limiter.counts()) to ensure scheduling.
//  - Use Bottleneck's events (limiter.on('failed', ...) ) to test retry logic if added.


services/logger.js
------------------
// logger.js
const fs = require('fs');
const path = require('path');

const logFile = path.join(__dirname, 'migration.log');
const logStream = fs.createWriteStream(logFile, { flags: 'a' });

function logToFile(level, ...args) {
    const timestamp = new Date().toISOString();
    const message = args.map(arg => {
        if (typeof arg === 'object') {
            try {
                return JSON.stringify(arg);
            } catch {
                return '[Unserializable object]';
            }
        }
        return String(arg);
    }).join(' ');

    logStream.write(`[${timestamp}] [${level}] ${message}\n`);
}

module.exports = {
    info: (...args) => {
        console.log(...args);
        logToFile('INFO', ...args);
    },
    error: (...args) => {
        console.error(...args);
        logToFile('ERROR', ...args);
    }
};

services/link_store.js
----------------------
// services/link_store.js
// ---------------------
// Tracks which source pages have been migrated by sharding each Link into its own JSON file.

const fs = require('fs').promises;
const path = require('path');
const Link = require('../models/Link');

const LINKS_DIR = path.resolve(__dirname, '../links');
const DEFAULT_MIGRATION_TYPE = 'tasks';

class LinkStore {
    constructor(dir) {
        this.dir = dir;
        // ensure links directory exists
        fs.mkdir(this.dir, { recursive: true }).catch(() => {});
    }

    _dirForType(migrationType = DEFAULT_MIGRATION_TYPE) {
        const dir = path.join(this.dir, migrationType);
        fs.mkdir(dir, { recursive: true }).catch(() => {});
        return dir;
    }

    /**
     * Check if a given sourceId has already been linked.
     * @param {string} sourceId
     * @param {string} migrationType
     * @returns {Promise<boolean>}
     */
    async hasSourceId(sourceId, migrationType = DEFAULT_MIGRATION_TYPE) {
        const dir = this._dirForType(migrationType);
        const file = path.join(dir, `${sourceId}.json`);
        try {
            await fs.access(file);
            return true;
        } catch {
            return false;
        }
    }


    /**
     * Save a Link object to disk, sharded by sourceId.
     * @param {Link} link
     * @param {string} migrationType
     * @returns {Promise<void>}
     */
    async save(link, migrationType = DEFAULT_MIGRATION_TYPE) {
        const dir = this._dirForType(migrationType);
        const file = path.join(dir, `${link.sourceId}.json`);
        await fs.writeFile(file, JSON.stringify(link, null, 2), 'utf-8');
    }

    /**
     * (Optional) Load an existing Link by sourceId.
     * @param {string} sourceId
     * @param {string} migrationType
     * @returns {Promise<Link>}
     */
    async load(sourceId, migrationType = DEFAULT_MIGRATION_TYPE) {
        const dir = this._dirForType(migrationType);
        const file = path.join(dir, `${sourceId}.json`);
        const content = await fs.readFile(file, 'utf-8');
        const data = JSON.parse(content);
        return new Link(data.sourceId, data.targetId, data.status, data.syncedAt);
    }
}

module.exports = new LinkStore(LINKS_DIR);

services/fetch_tasks.js
-----------------------
// services/fetch_tasks.js
// ----------------------
// Streams pages (tasks) from a Notion database (DB A) one by one.

const notion = require('./notion_client');

async function* getTasksFromDBA(dbId) {
    let cursor = undefined;

    do {
        const response = await notion.databases.query({
            database_id: dbId,
            page_size: 100,
            start_cursor: cursor,
        });

        for (const page of response.results) {
            yield page;
        }

        cursor = response.has_more ? response.next_cursor : undefined;
    } while (cursor);
}

module.exports = { getTasksFromDBA };

services/relation_resolver.js
-----------------------------
// services/relation_resolver.js
// -----------------------------
// General-purpose helper for resolving or creating Notion relation pages.
// For a given target relation field on a database, this will:
//   1. Dynamically fetch the “relation” database ID (cache it).
//   2. For each source name:
//        • Query the relation-database for an existing page whose Name matches.
//        • If found, reuse its page ID.
//        • If not found, create a new page (setting only the Name property).
//   3. Return an array of `{ id: <page-id> }` suitable for a Notion “relation” property.
//
// Usage (from a transformer hook):
//   const { resolveOrCreateRelationPages } = require('../services/relation_resolver');
//   …
//   const relationRefs = await resolveOrCreateRelationPages({
//     targetDbId: CENT_DB_ID,
//     relationPropName: 'People',
//     sourceNames: ['Alice', 'Bob'],
//     nameProp: 'Name'
//   });
//   // relationRefs is now something like:
//   // [ { id: 'xxxx-xxxx-xxxx' }, { id: 'yyyy-yyyy-yyyy' } ]
//
// Notes:
//   • Caches relation DB IDs per (targetDbId, relationPropName) to avoid
//     repeated notion.databases.retrieve calls.
//   • Looks up by exact “Name” match; if multiple pages match, picks the first and logs a warning.
//   • Creates a new page with only the `nameProp` (title) when no existing match is found.
//   • Throws if `relationPropName` is not actually a relation field on `targetDbId`.

const notion = require('./notion_client');
const Bottleneck = require('bottleneck');

// In-memory cache for relation database IDs, keyed by `${targetDbId}|${relationPropName}`
const relationDbCache = {};

/**
 * Fetches (and caches) the database ID that the given relation property points to.
 *
 * @param {string} targetDbId         - The Notion database ID in which the relation property lives.
 * @param {string} relationPropName   - The name of the relation property (e.g. "People", "Brands").
 * @returns {Promise<string>}         - The related database's ID.
 * @throws {Error}                    - If the property doesn’t exist or isn’t a relation.
 */
async function getRelationDbId(targetDbId, relationPropName) {
    const cacheKey = `${targetDbId}|${relationPropName}`;
    if (relationDbCache[cacheKey]) {
        return relationDbCache[cacheKey];
    }

    const dbSchema = await notion.databases.retrieve({ database_id: targetDbId });
    const prop = dbSchema.properties[relationPropName];
    if (!prop) {
        throw new Error(`Property "${relationPropName}" not found on database ${targetDbId}.`);
    }
    if (prop.type !== 'relation' || !prop.relation || !prop.relation.database_id) {
        throw new Error(`Property "${relationPropName}" on database ${targetDbId} is not a relation field.`);
    }

    const relatedDbId = prop.relation.database_id;
    relationDbCache[cacheKey] = relatedDbId;
    return relatedDbId;
}

/**
 * Searches a Notion database for a page whose `nameProp` equals `name`.
 *
 * @param {string} relationDbId    - The ID of the database to query.
 * @param {string} nameProp        - The name of the title property to filter on (usually "Name").
 * @param {string} name            - The exact string to match.
 * @returns {Promise<string|null>} - The first matching page ID, or null if none found.
 */
async function findPageByName(relationDbId, nameProp, name) {
    // Notion filters for a title property look like `{ property: nameProp, title: { equals: name } }`
    const response = await notion.databases.query({
        database_id: relationDbId,
        page_size: 2, // we only need to know if ≥1 exist
        filter: {
            property: nameProp,
            title: {
                equals: name
            }
        }
    });

    if (response.results.length > 1) {
        console.warn(
            `Warning: Multiple pages found in DB ${relationDbId} where "${nameProp}" == "${name}". ` +
            `Using the first result (ID: ${response.results[0].id}).`
        );
    }

    return response.results.length > 0 ? response.results[0].id : null;
}

/**
 * Creates a new page in the given database with only the title property set to `name`.
 *
 * @param {string} relationDbId    - The ID of the database in which to create the page.
 * @param {string} nameProp        - The name of the title property (usually "Name").
 * @param {string} name            - The string value to set on that title property.
 * @returns {Promise<string>}      - The newly created page's ID.
 */
async function createPageWithName(relationDbId, nameProp, name) {
    // Build the minimal “properties” payload for a new page with only a title.
    const properties = {
        [nameProp]: {
            title: [
                {
                    text: {
                        content: name
                    }
                }
            ]
        }
    };

    const response = await notion.pages.create({
        parent: { database_id: relationDbId },
        properties
    });

    return response.id;
}

/**
 * For a list of source names, resolves or creates pages in the target relation database.
 *
 * @param {Object}   options
 * @param {string}   options.targetDbId         - The ID of the database containing the relation property.
 * @param {string}   options.relationPropName   - The name of the relation property on targetDbId.
 * @param {string[]} options.sourceNames        - Array of strings (e.g., ["Alice", "Bob"]) to resolve.
 * @param {string}   options.nameProp           - The title property key in the relation DB (usually "Name").
 * @returns {Promise<string[]>}                 - Array of page IDs, in the same order as `sourceNames`.
 *
 * @throws {Error} If any underlying API calls fail, or if the relation property is misconfigured.
 */
async function resolveOrCreateRelationPages({ targetDbId, relationPropName, sourceNames, nameProp }) {
    if (!Array.isArray(sourceNames)) {
        throw new Error(`sourceNames must be an array of strings.`);
    }

    // 1) Resolve the actual DB ID that this relation property points to (with caching).
    const relationDbId = await getRelationDbId(targetDbId, relationPropName);

    const resolvedIds = [];

    // 2) For each source name, find or create a page.
    for (const name of sourceNames) {
        if (typeof name !== 'string' || name.trim() === '') {
            // Skip empty names; return null or handle as desired.
            continue;
        }

        // 2a) Try to find an existing page by name.
        let pageId = await findPageByName(relationDbId, nameProp, name);

        // 2b) If none found, create a new page with that name.
        if (!pageId) {
            pageId = await createPageWithName(relationDbId, nameProp, name);
            console.log(`Created new relation page in DB ${relationDbId} with ${nameProp}="${name}", ID=${pageId}`);
        }

        resolvedIds.push(pageId);
    }

    return resolvedIds;
}

module.exports = {
    resolveOrCreateRelationPages
};
